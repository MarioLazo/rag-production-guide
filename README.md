<div align="center">

# ğŸ” RAG Production Guide

### A Practitioner's Handbook for Building RAG Systems That Actually Work

[![MIT License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](CONTRIBUTING.md)
[![Contributors](https://img.shields.io/github/contributors/MarioLazo/rag-production-guide)](https://github.com/MarioLazo/rag-production-guide/graphs/contributors)

**80% of enterprise RAG projects fail.** This guide shows you how to be in the 20% that succeed.

[Why RAG Fails](#-why-rag-fails) â€¢
[Architecture](#-architecture) â€¢
[Case Studies](#-case-studies) â€¢
[Cheatsheets](#-cheatsheets) â€¢
[Platform Guides](#-platform-guides) â€¢
[Contributing](#-contributing)

</div>

---

## ğŸ“– About This Guide

This repository distills findings from **30+ authoritative sources** â€” including research from IBM, OpenAI, Anthropic, Microsoft, AWS, Google, NVIDIA, and leading open-source frameworks â€” combined with **real-world production experience** across healthcare, manufacturing, and enterprise deployments.

> **The core insight:** The "vector DB + LLM" recipe that dominates blog posts fails in practice. Success requires **modular architecture**, **hybrid retrieval**, **rigorous evaluation**, and **deliberate cost engineering**.

### Who This Is For

| Role | What You'll Get |
|------|-----------------|
| ğŸ”§ **ML/AI Engineers** | Implementation patterns, code examples, evaluation frameworks |
| ğŸ—ï¸ **Solution Architects** | Architecture decisions, platform comparisons, integration patterns |
| ğŸ“Š **Technical Leaders** | ROI frameworks, risk assessment, vendor evaluation criteria |

---

## ğŸš¨ Why RAG Fails

<div align="center">

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    THE STARK REALITY                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ“‰ 80% of enterprise RAG projects end in failure               â”‚
â”‚  ğŸ“‰ 40-60% never reach production                               â”‚
â”‚  ğŸ’° $13.8 billion in enterprise AI spending at risk             â”‚
â”‚  ğŸ“‰ 42% of AI projects failed in 2025 (2.5Ã— increase from 2024) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```
*Sources: PIMCO 2025 Analysis, TMLS Insights, Gartner Research*

</div>

### The Seven Silent Killers

| # | Failure Mode | Stage | Impact |
|---|-------------|-------|--------|
| 1 | **Missed Retrieval** | Retrieval | Relevant documents don't surface |
| 2 | **Context Misalignment** | Retrieval | Retrieved content doesn't match intent |
| 3 | **Stale Indexes** | Retrieval | Data drift causes outdated responses |
| 4 | **Hallucination** | Generation | LLM fabricates content not in context |
| 5 | **Lost-in-the-Middle** | Generation | LLM ignores middle of context window |
| 6 | **Semantic Collapse** | System | Inter-document similarity > 0.65 causes degradation |
| 7 | **Compounding Errors** | System | 95% accuracy per layer = 81% end-to-end across 5 layers |

> ğŸ“š **Deep Dive:** [Failure Modes & How to Prevent Them](docs/02-failure-modes.md)

---

## ğŸ—ï¸ Architecture

### The Modular RAG Pattern

```mermaid
flowchart LR
    subgraph Ingestion["ğŸ“¥ Ingestion"]
        A[Documents] --> B[Chunking]
        B --> C[Embedding]
        C --> D[(Vector Store)]
    end
    
    subgraph Retrieval["ğŸ” Retrieval"]
        E[Query] --> F{Hybrid Search}
        F -->|BM25| D
        F -->|Vector| D
        D --> G[Reranker]
    end
    
    subgraph Generation["âœ¨ Generation"]
        G --> H[Context Assembly]
        H --> I[LLM]
        I --> J[Response + Citations]
    end
    
    style Ingestion fill:#e1f5fe
    style Retrieval fill:#fff3e0
    style Generation fill:#e8f5e9
```

### Key Architectural Insights

| Component | Recommendation | Why |
|-----------|---------------|-----|
| **Chunking** | 400-512 tokens, 10-20% overlap | 80% of failures trace back to chunking decisions |
| **Search** | Hybrid BM25 + Vector with RRF | Pure vector search has fundamental bottlenecks |
| **Reranking** | Cross-encoder on top-20 results | 49-67% retrieval failure reduction |
| **Context** | Contextual Retrieval preprocessing | Single highest-ROI improvement available |

> ğŸ“š **Deep Dives:**
> - [Chunking Strategies](docs/03-chunking-strategies.md)
> - [Hybrid Search](docs/04-hybrid-search.md)
> - [Advanced Patterns](docs/05-advanced-patterns.md)

---

## ğŸ“‹ Case Studies

Real-world production experiences with anonymized details. Each case study includes:
- âœ… Business context and scale
- âŒ What failed and why
- âœ… What worked and lessons learned
- ğŸ”§ Technical architecture patterns

| Case Study | Industry | Scale | Key Learning |
|------------|----------|-------|--------------|
| [Healthcare Document AI](case-studies/01-healthcare-document-ai.md) | Healthcare | 8-12K docs/month | Taxonomy design is a data quality issue |
| [Technical Support Agent](case-studies/02-medtech-support-agent.md) | Medical Devices | 75-125K cases/year | Decision tree + RAG hybrid outperforms open-ended RAG |
| [Knowledge Mining Bot](case-studies/03-enterprise-knowledge-bot.md) | Enterprise SaaS | 10K-100K docs | Freshness is a trust issue, not just a data issue |

> ğŸ“š **Framework:** [The 5 Danger Zones](case-studies/README.md#the-5-danger-zones)

---

## ğŸ“Š Cheatsheets

Quick-reference guides for common decisions:

| Cheatsheet | Description |
|------------|-------------|
| [ğŸŒ³ Chunking Decision Tree](cheatsheets/chunking-decision-tree.md) | Visual guide for chunk size selection |
| [âš–ï¸ Hybrid Search Weights](cheatsheets/hybrid-search-weights.md) | Domain-specific BM25/vector weights |
| [ğŸš¨ Danger Zones Checklist](cheatsheets/danger-zones-checklist.md) | Pre-flight checklist before production |
| [ğŸ“ Evaluation Metrics](cheatsheets/evaluation-metrics.md) | RAG Triad + extended metrics |
| [ğŸ’° Cost Optimization](cheatsheets/cost-optimization.md) | From $18K/month to sustainable |

---

## â˜ï¸ Platform Guides

Practical implementation guidance for major platforms:

| Platform | Guide | Key Services |
|----------|-------|--------------|
| ![AWS](https://img.shields.io/badge/AWS-232F3E?style=flat&logo=amazon-aws&logoColor=white) | [AWS Bedrock](docs/platform-guides/aws-bedrock.md) | Bedrock, Kendra, OpenSearch, S3 Vectors |
| ![Azure](https://img.shields.io/badge/Azure-0078D4?style=flat&logo=microsoft-azure&logoColor=white) | [Azure AI](docs/platform-guides/azure-ai-search.md) | AI Search, OpenAI Service, Document Intelligence |
| ![GCP](https://img.shields.io/badge/GCP-4285F4?style=flat&logo=google-cloud&logoColor=white) | [Google Vertex AI](docs/platform-guides/gcp-vertex-ai.md) | Vertex AI Search, Gemini, Document AI |
| ![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=flat&logo=databricks&logoColor=white) | [Databricks](docs/platform-guides/databricks-mosaic.md) | Mosaic AI, Vector Search, MLflow |
| ![UiPath](https://img.shields.io/badge/UiPath-FA4616?style=flat&logo=uipath&logoColor=white) | [UiPath](docs/platform-guides/uipath-automation.md) | AI Center, Document Understanding, Orchestrator |

---

## ğŸ“ˆ Evaluation Framework

The industry-standard **RAG Triad**:

```mermaid
flowchart TD
    subgraph Triad["ğŸ“ RAG Triad"]
        A[Answer Relevancy] 
        B[Faithfulness]
        C[Context Relevancy]
    end
    
    A -->|"Is the response relevant<br/>to the question?"| Q[Query]
    B -->|"Is the response grounded<br/>in retrieved context?"| R[Response]
    C -->|"Is the retrieved context<br/>relevant?"| D[Documents]
```

| Tool | Stars | Best For |
|------|-------|----------|
| [RAGAS](https://github.com/explodinggradients/ragas) | ~12K | Reference-free evaluation, synthetic test data |
| [DeepEval](https://github.com/confident-ai/deepeval) | ~12K | CI/CD integration, 50+ metrics, red-teaming |
| [AutoRAG](https://github.com/Marker-Inc-Korea/AutoRAG) | ~5K | AutoML-style pipeline optimization |

> ğŸ“š **Deep Dive:** [Evaluation Framework](docs/06-evaluation-framework.md)

---

## ğŸ’° Cost Engineering

RAG costs grow **exponentially**, not linearly. A documented case reached **$18K/month** before optimization.

| Optimization | Savings | Implementation |
|-------------|---------|----------------|
| **Semantic Caching** | 18-68% | Cache query-response pairs by embedding similarity |
| **Model Routing** | 30-80% | Route simple queries to cheaper models |
| **Prompt Optimization** | Up to 35% | Concise instructions, context pruning |
| **Batch Inference** | 50% | Non-real-time workloads |

**Total potential savings: 70-85%** with the full optimization stack.

> ğŸ“š **Deep Dive:** [Cost Engineering](docs/07-cost-engineering.md)

---

## ğŸ¤ Contributing

We welcome contributions from the community! This guide improves with diverse production experiences.

### Ways to Contribute

- ğŸ› Report errors or outdated information
- ğŸ“ Add anonymized case studies from your experience
- ğŸ”§ Improve platform-specific examples
- ğŸŒ Translate to other languages
- ğŸ“Š Add diagrams or visualizations

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ™ Acknowledgments

This guide stands on the shoulders of giants. We're deeply grateful to:

### Open Source Community
- **[RAGFlow](https://github.com/infiniflow/ragflow)** by InfiniFlow â€” Production-ready RAG with deep document understanding
- **[RAGAS](https://github.com/explodinggradients/ragas)** by Exploding Gradients â€” Reference-free evaluation framework
- **[DeepEval](https://github.com/confident-ai/deepeval)** by Confident AI â€” Production testing with 50+ metrics
- **[AutoRAG](https://github.com/Marker-Inc-Korea/AutoRAG)** by Marker Inc â€” AutoML-style pipeline optimization
- **[Athina AI Cookbooks](https://github.com/athina-ai/rag-cookbooks)** â€” Complete taxonomy from Naive â†’ Agentic

### Enterprise & Research
- **Microsoft** â€” Azure AI Search, GraphRAG, GPT-RAG patterns
- **AWS** â€” Bedrock samples, RAG reference architectures
- **Google** â€” Vertex AI, Gemini integration patterns
- **Databricks** â€” GenAI Cookbook, MLflow evaluation
- **NVIDIA** â€” GPU-accelerated RAG blueprints
- **IBM** â€” Granite community cookbooks

See [ACKNOWLEDGMENTS.md](ACKNOWLEDGMENTS.md) for the complete list.

---

## ğŸ“š Resources

- [Official Vendor Repositories](resources/official-vendor-repos.md)
- [Community Projects](resources/community-repos.md)
- [Further Reading](resources/further-reading.md)
- [Glossary](resources/glossary.md)

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

<div align="center">

**Built with â¤ï¸ by practitioners, for practitioners**

[â¬† Back to Top](#-rag-production-guide)

</div>
